{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d4c7b5b5",
      "metadata": {},
      "source": [
        "# Cold-Start Recommender Workflow\n",
        "This notebook prepares a strict new-item MovieLens split, fits leakage-safe text encoders, and benchmarks content-to-factor models including CTR-lite, A2F, CTPF, CDL, HFT, MICM, and the counterfactual CMCL baseline with pseudo-exposure modeling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a651a5c5",
      "metadata": {},
      "source": [
        "## Notebook outline\n",
        "1. Configure dataset paths plus encoder/back-end toggles.\n",
        "2. Prepare warm/val/test assets with the leakage-safe text encoder.\n",
        "3. Train MF + requested content models (incl. MICM/CMCL) with pseudo-exposure estimation.\n",
        "4. Inspect saved artefacts, exposure checkpoints, and evaluation metrics (point estimates, CIs, buckets, and deltas).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8eba43b0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(WindowsPath('C:/Users/user/PGMS_Rec_Systems/PGMS_for_Recommender_Systems/coldstart/data/movielens_latest_small.csv'),\n",
              " WindowsPath('C:/Users/user/PGMS_Rec_Systems/PGMS_for_Recommender_Systems/coldstart/output/notebook_run_20251029_223545'))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def locate_project_root() -> Path:\n",
        "    current = Path.cwd().resolve()\n",
        "    for candidate in (current, *current.parents):\n",
        "        if (candidate / \"coldstart\" / \"src\").exists():\n",
        "            return candidate\n",
        "    raise RuntimeError(\"Cannot locate project root containing 'coldstart/src'.\")\n",
        "\n",
        "\n",
        "PROJECT_ROOT = locate_project_root()\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "from coldstart.src.notebook_utils import _read_simple_yaml\n",
        "from coldstart.src.notebook_utils import build_interaction_frame\n",
        "from coldstart.src import data_io, pipeline\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / \"coldstart\" / \"data\"\n",
        "DATASET_VARIANT = \"small\"  # use 'medium' for the full benchmark\n",
        "DATA_PATH = DATA_DIR / f\"movielens_latest_{DATASET_VARIANT}.csv\"\n",
        "CONFIG_PATH = PROJECT_ROOT / \"coldstart\" / \"configs\" / \"base.yaml\"\n",
        "OUTPUT_ROOT = PROJECT_ROOT / \"coldstart\" / \"output\"\n",
        "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if not DATA_PATH.exists():\n",
        "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    df = build_interaction_frame(dataset=DATASET_VARIANT)\n",
        "    df.to_csv(DATA_PATH, index=False)\n",
        "    print(f\"Downloaded MovieLens {DATASET_VARIANT} interactions to {DATA_PATH}\")\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "RUN_DIR = OUTPUT_ROOT / f\"notebook_run_{timestamp}\"\n",
        "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "DATA_PATH, RUN_DIR\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "447c0a22",
      "metadata": {},
      "source": [
        "## Prepare the cold-start split\n",
        "We parse the lightweight configuration file, run the strict new-item split (optionally reserving validation items), normalise title+genre+tag text, and fit the chosen encoder on warm items only.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "50139869",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 100836 interactions from C:\\Users\\user\\PGMS_Rec_Systems\\PGMS_for_Recommender_Systems\\coldstart\\data\\movielens_latest_small.csv.\n",
            "Dataset contains 610 unique users and 9724 unique items.\n",
            "Using 100836 interactions out of the source data (limit=1200000).\n",
            "TF-IDF fit on warm only\n",
            "Warm text features shape: (7779, 128)\n",
            "Cold text features shape: (1945, 128)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['cold_interactions.csv',\n",
              " 'cold_item_ids.json',\n",
              " 'cold_item_ids.txt',\n",
              " 'cold_item_text_features.json',\n",
              " 'tfidf_state.json',\n",
              " 'warm_interactions.csv',\n",
              " 'warm_item_ids.json',\n",
              " 'warm_item_text_features.json']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from importlib import reload\n",
        "from coldstart.src.models import ctpf, hft\n",
        "reload(data_io)\n",
        "reload(ctpf)\n",
        "reload(hft)\n",
        "reload(pipeline)\n",
        "\n",
        "config = _read_simple_yaml(CONFIG_PATH)\n",
        "tfidf_params = config.get(\"tfidf\", {})\n",
        "prepare_cfg = config.get(\"prepare\", {})\n",
        "text_encoder_cfg = config.get(\"text_encoder\", {})\n",
        "encoder_type = text_encoder_cfg.get(\"type\", \"tfidf\")\n",
        "encoder_params = text_encoder_cfg.get(\"params\")\n",
        "if encoder_params is None and encoder_type == \"tfidf\":\n",
        "    encoder_params = tfidf_params\n",
        "\n",
        "seed = int(prepare_cfg.get(\"seed\", 42) or 42)\n",
        "cold_item_frac = float(prepare_cfg.get(\"cold_item_frac\", 0.2) or 0.2)\n",
        "val_item_frac = float(prepare_cfg.get(\"val_item_frac\", 0) or 0)\n",
        "val_item_frac = val_item_frac if val_item_frac > 0 else None\n",
        "interaction_limit = int(prepare_cfg.get(\"interaction_limit\", 0) or 0) or None\n",
        "\n",
        "pipeline.prepare_dataset(\n",
        "    DATA_PATH,\n",
        "    RUN_DIR,\n",
        "    tfidf_params=tfidf_params,\n",
        "    encoder_type=encoder_type,\n",
        "    encoder_params=encoder_params,\n",
        "    cold_item_frac=cold_item_frac,\n",
        "    val_item_frac=val_item_frac,\n",
        "    seed=seed,\n",
        "    interaction_limit=interaction_limit,\n",
        ")\n",
        "sorted(p.name for p in RUN_DIR.iterdir())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1ce945e",
      "metadata": {},
      "source": [
        "## Train and evaluate\n",
        "Compare CTR-lite, A2F, CTPF, CDL, HFT, MICM, and CMCL on the prepared split. Set `model_choice = \"all\"` to evaluate every option (Torch backend required for MICM/CMCL). Each CMCL run automatically (re)trains the pseudo-exposure estimator if a cached checkpoint is missing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "27b44f19",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 80541 interactions from C:\\Users\\user\\PGMS_Rec_Systems\\PGMS_for_Recommender_Systems\\coldstart\\output\\notebook_run_20251029_223545\\warm_interactions.csv.\n",
            "Dataset contains 610 unique users and 7779 unique items.\n",
            "Loaded 20295 interactions from C:\\Users\\user\\PGMS_Rec_Systems\\PGMS_for_Recommender_Systems\\coldstart\\output\\notebook_run_20251029_223545\\cold_interactions.csv.\n",
            "Dataset contains 609 unique users and 1945 unique items.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'ctrlite': {'hit@5': 0.047619047619047616,\n",
              "  'ndcg@5': 0.01063449180480855,\n",
              "  'evaluated_users': 609},\n",
              " 'a2f': {'hit@5': 0.09688013136288999,\n",
              "  'ndcg@5': 0.020248667237844895,\n",
              "  'evaluated_users': 609},\n",
              " 'ctpf': {'hit@5': 0.10016420361247948,\n",
              "  'ndcg@5': 0.03560659161553215,\n",
              "  'evaluated_users': 609},\n",
              " 'cdl': {'hit@5': 0.03284072249589491,\n",
              "  'ndcg@5': 0.005631455778430841,\n",
              "  'evaluated_users': 609},\n",
              " 'hft': {'hit@5': 0.10016420361247948,\n",
              "  'ndcg@5': 0.032112409367314576,\n",
              "  'evaluated_users': 609}}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_choice = \"micm,cmcl\"  # options: 'ctrlite', 'a2f', 'ctpf', 'cdl', 'hft', 'micm', 'cmcl', 'all'\n",
        "run_adaptive = False  # only used by ctrlite; ignored otherwise\n",
        "prefer_gpu = True\n",
        "lf_model_choice = model_choice.strip().lower()\n",
        "torch_only = {\"micm\", \"cmcl\"}\n",
        "if lf_model_choice == \"all\":\n",
        "    backend_choice = \"torch\"\n",
        "else:\n",
        "    requested = [part.strip().lower() for part in model_choice.split(',') if part.strip()]\n",
        "    backend_choice = \"torch\" if any(model in torch_only for model in requested) else \"numpy\"\n",
        "\n",
        "mf_cfg = config.get(\"mf\", {})\n",
        "ctrlite_cfg = config.get(\"ctrlite\", {})\n",
        "a2f_cfg = config.get(\"a2f\", {})\n",
        "ctpf_cfg = config.get(\"ctpf\", {})\n",
        "cdl_cfg = config.get(\"cdl\", {})\n",
        "hft_cfg = config.get(\"hft\", {})\n",
        "micm_cfg = config.get(\"micm\", {})\n",
        "cmcl_cfg = config.get(\"cmcl\", {})\n",
        "\n",
        "results = pipeline.train_and_evaluate_content_model(\n",
        "    RUN_DIR,\n",
        "    k_factors=16,\n",
        "    k_eval=[5, 10],\n",
        "    mf_reg=float(mf_cfg.get(\"reg\", 0.02)),\n",
        "    mf_iters=int(mf_cfg.get(\"iters\", 30)),\n",
        "    mf_lr=float(mf_cfg.get(\"lr\", 0.02)),\n",
        "    seed=seed,\n",
        "    ctrlite_reg=float(ctrlite_cfg.get(\"reg\", 0.01)),\n",
        "    ctrlite_lr=float(ctrlite_cfg.get(\"lr\", 0.1)),\n",
        "    ctrlite_iters=int(ctrlite_cfg.get(\"iters\", 80)),\n",
        "    adaptive=run_adaptive and model_choice == \"ctrlite\",\n",
        "    model=model_choice,\n",
        "    a2f_cfg=a2f_cfg,\n",
        "    ctpf_cfg=ctpf_cfg,\n",
        "    cdl_cfg=cdl_cfg,\n",
        "    hft_cfg=hft_cfg,\n",
        "    micm_cfg=micm_cfg,\n",
        "    cmcl_cfg=cmcl_cfg,\n",
        "    mf_cfg=mf_cfg,\n",
        "    backend=backend_choice,\n",
        "    prefer_gpu=prefer_gpu,\n",
        ")\n",
        "results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect the evaluation dictionary\n",
        "Each model now reports point estimates, 95% bootstrap confidence intervals, per-bucket breakdowns (item text length, item popularity, user history length), and `delta_vs_micm` whenever MICM is part of the run. Use the snippet below to explore the nested structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "pprint(results)\n",
        "\n",
        "if \"cmcl\" in results:\n",
        "    bucket_snapshot = results[\"cmcl\"].get(\"buckets\", {})\n",
        "    print(\"\n",
        "CMCL bucket snapshot:\")\n",
        "    print(json.dumps(bucket_snapshot, indent=2)[:2000])\n",
        "    delta = results[\"cmcl\"].get(\"delta_vs_micm\")\n",
        "    if delta:\n",
        "        print(\"\n",
        "Delta vs MICM:\")\n",
        "        print(json.dumps(delta, indent=2)[:2000])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2c78965e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 80541 interactions from C:\\Users\\user\\PGMS_Rec_Systems\\PGMS_for_Recommender_Systems\\coldstart\\output\\notebook_run_20251029_223545\\warm_interactions.csv.\n",
            "Dataset contains 610 unique users and 7779 unique items.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'user_id': '1',\n",
              "  'item_id': '1',\n",
              "  'rating_or_y': 4.0,\n",
              "  'item_text': 'Toy Story (1995) Adventure Animation Children Comedy Fantasy'},\n",
              " {'user_id': '1',\n",
              "  'item_id': '3',\n",
              "  'rating_or_y': 4.0,\n",
              "  'item_text': 'Grumpier Old Men (1995) Comedy Romance'},\n",
              " {'user_id': '1',\n",
              "  'item_id': '6',\n",
              "  'rating_or_y': 4.0,\n",
              "  'item_text': 'Heat (1995) Action Crime Thriller'}]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "warm_rows = data_io.load_interactions(RUN_DIR / \"warm_interactions.csv\")\n",
        "warm_rows[:3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "0e39a64f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "coldstart\\output\\notebook_run_20251029_223545\\cold_interactions.csv (1239615 bytes)\n",
            "coldstart\\output\\notebook_run_20251029_223545\\cold_item_ids.json (22354 bytes)\n",
            "coldstart\\output\\notebook_run_20251029_223545\\cold_item_ids.txt (12626 bytes)\n",
            "coldstart\\output\\notebook_run_20251029_223545\\cold_item_text_features.json (1395387 bytes)\n",
            "coldstart\\output\\notebook_run_20251029_223545\\models\\U.json (92740 bytes)\n",
            "coldstart\\output\\notebook_run_20251029_223545\\models\\V_warm.json (1182263 bytes)\n",
            "coldstart\\output\\notebook_run_20251029_223545\\tfidf_state.json (6049 bytes)\n",
            "coldstart\\output\\notebook_run_20251029_223545\\warm_interactions.csv (4871313 bytes)\n",
            "coldstart\\output\\notebook_run_20251029_223545\\warm_item_ids.json (89748 bytes)\n",
            "coldstart\\output\\notebook_run_20251029_223545\\warm_item_text_features.json (5591572 bytes)\n"
          ]
        }
      ],
      "source": [
        "for path in sorted(RUN_DIR.rglob(\"*\")):\n",
        "    if path.is_file():\n",
        "        rel_path = path.relative_to(PROJECT_ROOT)\n",
        "        size = path.stat().st_size\n",
        "        print(f\"{rel_path} ({size} bytes)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}