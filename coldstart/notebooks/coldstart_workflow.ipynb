{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "id":  "d4c7b5b5",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# Cold-Start Recommender Workflow\n",
                                     "This notebook prepares a strict new-item MovieLens split, fits leakage-safe text encoders, and benchmarks content-to-factor models including CTR-lite, A2F, CTPF, CDL, HFT, MICM, and the counterfactual CMCL baseline with pseudo-exposure modeling.\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "a651a5c5",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Notebook outline\n",
                                     "1. Configure dataset paths plus encoder/back-end toggles.\n",
                                     "2. Prepare warm/val/test assets with the leakage-safe text encoder.\n",
                                     "3. Train MF + requested content models (incl. MICM/CMCL) with pseudo-exposure estimation.\n",
                                     "4. Inspect saved artefacts, exposure checkpoints, and evaluation metrics (point estimates, CIs, buckets, and deltas).\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  19,
                      "id":  "8eba43b0",
                      "metadata":  {

                                   },
                      "outputs":  [
                                      {
                                          "data":  {
                                                       "text/plain":  [
                                                                          "(WindowsPath(\u0027C:/Users/user/PGMS_Rec_Systems/PGMS_for_Recommender_Systems/coldstart/data/movielens_latest_small.csv\u0027),\n",
                                                                          " WindowsPath(\u0027C:/Users/user/PGMS_Rec_Systems/PGMS_for_Recommender_Systems/coldstart/output/notebook_run_20251029_223545\u0027))"
                                                                      ]
                                                   },
                                          "execution_count":  19,
                                          "metadata":  {

                                                       },
                                          "output_type":  "execute_result"
                                      }
                                  ],
                      "source":  [
                                     "from datetime import datetime",
                                     "from pathlib import Path",
                                     "import sys",
                                     "",
                                     "",
                                     "def locate_project_root() -\u003e Path:",
                                     "    current = Path.cwd().resolve()",
                                     "    for candidate in (current, *current.parents):",
                                     "        if (candidate / \"coldstart\" / \"src\").exists():",
                                     "            return candidate",
                                     "    raise RuntimeError(\"Cannot locate project root containing \u0027coldstart/src\u0027.\")",
                                     "",
                                     "",
                                     "PROJECT_ROOT = locate_project_root()",
                                     "if str(PROJECT_ROOT) not in sys.path:",
                                     "    sys.path.insert(0, str(PROJECT_ROOT))",
                                     "",
                                     "from coldstart.src.notebook_utils import (",
                                     "    _read_simple_yaml,",
                                     "    build_amazon_interaction_frame,",
                                     "    build_interaction_frame,",
                                     ")",
                                     "from coldstart.src import data_io, pipeline",
                                     "",
                                     "DATA_SOURCE = \"movielens\"  # options: \u0027movielens\u0027 or \u0027amazon\u0027",
                                     "DATASET_VARIANT = \"small\"  # only used for MovieLens",
                                     "AMAZON_VARIANT = \"beauty\"  # only used when DATA_SOURCE == \u0027amazon\u0027",
                                     "DATA_DIR = PROJECT_ROOT / \"coldstart\" / \"data\"",
                                     "if DATA_SOURCE == \"amazon\":",
                                     "    DATA_PATH = DATA_DIR / f\"amazon_{AMAZON_VARIANT}.csv\"",
                                     "else:",
                                     "    DATA_PATH = DATA_DIR / f\"movielens_latest_{DATASET_VARIANT}.csv\"",
                                     "CONFIG_PATH = PROJECT_ROOT / \"coldstart\" / \"configs\" / \"base.yaml\"",
                                     "OUTPUT_ROOT = PROJECT_ROOT / \"coldstart\" / \"output\"",
                                     "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)",
                                     "",
                                     "if not DATA_PATH.exists():",
                                     "    DATA_DIR.mkdir(parents=True, exist_ok=True)",
                                     "    if DATA_SOURCE == \"amazon\":",
                                     "        df = build_amazon_interaction_frame(dataset=AMAZON_VARIANT, cache_dir=DATA_DIR)",
                                     "        source_name = f\"Amazon {AMAZON_VARIANT}\"",
                                     "    else:",
                                     "        df = build_interaction_frame(dataset=DATASET_VARIANT)",
                                     "        source_name = f\"MovieLens {DATASET_VARIANT}\"",
                                     "    df.to_csv(DATA_PATH, index=False)",
                                     "    print(f\"Downloaded {source_name} interactions to {DATA_PATH}\")",
                                     "",
                                     "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")",
                                     "RUN_DIR = OUTPUT_ROOT / f\"notebook_run_{timestamp}\"",
                                     "RUN_DIR.mkdir(parents=True, exist_ok=True)",
                                     "",
                                     "DATA_PATH, RUN_DIR"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "447c0a22",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Prepare the cold-start split\n",
                                     "We parse the lightweight configuration file, run the strict new-item split (optionally reserving validation items), normalise title+genre+tag text, and fit the chosen encoder on warm items only.\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  20,
                      "id":  "50139869",
                      "metadata":  {

                                   },
                      "outputs":  [
                                      {
                                          "name":  "stdout",
                                          "output_type":  "stream",
                                          "text":  [
                                                       "Loaded 100836 interactions from C:\\Users\\user\\PGMS_Rec_Systems\\PGMS_for_Recommender_Systems\\coldstart\\data\\movielens_latest_small.csv.\n",
                                                       "Dataset contains 610 unique users and 9724 unique items.\n",
                                                       "Using 100836 interactions out of the source data (limit=1200000).\n",
                                                       "TF-IDF fit on warm only\n",
                                                       "Warm text features shape: (7779, 128)\n",
                                                       "Cold text features shape: (1945, 128)\n"
                                                   ]
                                      },
                                      {
                                          "data":  {
                                                       "text/plain":  [
                                                                          "[\u0027cold_interactions.csv\u0027,\n",
                                                                          " \u0027cold_item_ids.json\u0027,\n",
                                                                          " \u0027cold_item_ids.txt\u0027,\n",
                                                                          " \u0027cold_item_text_features.json\u0027,\n",
                                                                          " \u0027tfidf_state.json\u0027,\n",
                                                                          " \u0027warm_interactions.csv\u0027,\n",
                                                                          " \u0027warm_item_ids.json\u0027,\n",
                                                                          " \u0027warm_item_text_features.json\u0027]"
                                                                      ]
                                                   },
                                          "execution_count":  20,
                                          "metadata":  {

                                                       },
                                          "output_type":  "execute_result"
                                      }
                                  ],
                      "source":  [
                                     "from importlib import reload\n",
                                     "from coldstart.src.models import ctpf, hft\n",
                                     "reload(data_io)\n",
                                     "reload(ctpf)\n",
                                     "reload(hft)\n",
                                     "reload(pipeline)\n",
                                     "\n",
                                     "config = _read_simple_yaml(CONFIG_PATH)\n",
                                     "tfidf_params = config.get(\"tfidf\", {})\n",
                                     "prepare_cfg = config.get(\"prepare\", {})\n",
                                     "text_encoder_cfg = config.get(\"text_encoder\", {})\n",
                                     "encoder_type = text_encoder_cfg.get(\"type\", \"tfidf\")\n",
                                     "encoder_params = text_encoder_cfg.get(\"params\")\n",
                                     "if encoder_params is None and encoder_type == \"tfidf\":\n",
                                     "    encoder_params = tfidf_params\n",
                                     "\n",
                                     "seed = int(prepare_cfg.get(\"seed\", 42) or 42)\n",
                                     "cold_item_frac = float(prepare_cfg.get(\"cold_item_frac\", 0.2) or 0.2)\n",
                                     "val_item_frac = float(prepare_cfg.get(\"val_item_frac\", 0) or 0)\n",
                                     "val_item_frac = val_item_frac if val_item_frac \u003e 0 else None\n",
                                     "interaction_limit = int(prepare_cfg.get(\"interaction_limit\", 0) or 0) or None\n",
                                     "\n",
                                     "pipeline.prepare_dataset(\n",
                                     "    DATA_PATH,\n",
                                     "    RUN_DIR,\n",
                                     "    tfidf_params=tfidf_params,\n",
                                     "    encoder_type=encoder_type,\n",
                                     "    encoder_params=encoder_params,\n",
                                     "    cold_item_frac=cold_item_frac,\n",
                                     "    val_item_frac=val_item_frac,\n",
                                     "    seed=seed,\n",
                                     "    interaction_limit=interaction_limit,\n",
                                     ")\n",
                                     "sorted(p.name for p in RUN_DIR.iterdir())\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "id":  "b1ce945e",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Train and evaluate\n",
                                     "Compare CTR-lite, A2F, CTPF, CDL, HFT, MICM, and CMCL on the prepared split. Set `model_choice = \"all\"` to evaluate every option (Torch backend required for MICM/CMCL). Each CMCL run automatically (re)trains the pseudo-exposure estimator if a cached checkpoint is missing.\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  21,
                      "id":  "27b44f19",
                      "metadata":  {

                                   },
                      "outputs":  [
                                      {
                                          "name":  "stdout",
                                          "output_type":  "stream",
                                          "text":  [
                                                       "Loaded 80541 interactions from C:\\Users\\user\\PGMS_Rec_Systems\\PGMS_for_Recommender_Systems\\coldstart\\output\\notebook_run_20251029_223545\\warm_interactions.csv.\n",
                                                       "Dataset contains 610 unique users and 7779 unique items.\n",
                                                       "Loaded 20295 interactions from C:\\Users\\user\\PGMS_Rec_Systems\\PGMS_for_Recommender_Systems\\coldstart\\output\\notebook_run_20251029_223545\\cold_interactions.csv.\n",
                                                       "Dataset contains 609 unique users and 1945 unique items.\n"
                                                   ]
                                      },
                                      {
                                          "data":  {
                                                       "text/plain":  [
                                                                          "{\u0027ctrlite\u0027: {\u0027hit@5\u0027: 0.047619047619047616,\n",
                                                                          "  \u0027ndcg@5\u0027: 0.01063449180480855,\n",
                                                                          "  \u0027evaluated_users\u0027: 609},\n",
                                                                          " \u0027a2f\u0027: {\u0027hit@5\u0027: 0.09688013136288999,\n",
                                                                          "  \u0027ndcg@5\u0027: 0.020248667237844895,\n",
                                                                          "  \u0027evaluated_users\u0027: 609},\n",
                                                                          " \u0027ctpf\u0027: {\u0027hit@5\u0027: 0.10016420361247948,\n",
                                                                          "  \u0027ndcg@5\u0027: 0.03560659161553215,\n",
                                                                          "  \u0027evaluated_users\u0027: 609},\n",
                                                                          " \u0027cdl\u0027: {\u0027hit@5\u0027: 0.03284072249589491,\n",
                                                                          "  \u0027ndcg@5\u0027: 0.005631455778430841,\n",
                                                                          "  \u0027evaluated_users\u0027: 609},\n",
                                                                          " \u0027hft\u0027: {\u0027hit@5\u0027: 0.10016420361247948,\n",
                                                                          "  \u0027ndcg@5\u0027: 0.032112409367314576,\n",
                                                                          "  \u0027evaluated_users\u0027: 609}}"
                                                                      ]
                                                   },
                                          "execution_count":  21,
                                          "metadata":  {

                                                       },
                                          "output_type":  "execute_result"
                                      }
                                  ],
                      "source":  [
                                     "model_choice = \"micm,cmcl\"  # options: \u0027ctrlite\u0027, \u0027a2f\u0027, \u0027ctpf\u0027, \u0027cdl\u0027, \u0027hft\u0027, \u0027micm\u0027, \u0027cmcl\u0027, \u0027all\u0027\n",
                                     "run_adaptive = False  # only used by ctrlite; ignored otherwise\n",
                                     "prefer_gpu = True\n",
                                     "lf_model_choice = model_choice.strip().lower()\n",
                                     "torch_only = {\"micm\", \"cmcl\"}\n",
                                     "if lf_model_choice == \"all\":\n",
                                     "    backend_choice = \"torch\"\n",
                                     "else:\n",
                                     "    requested = [part.strip().lower() for part in model_choice.split(\u0027,\u0027) if part.strip()]\n",
                                     "    backend_choice = \"torch\" if any(model in torch_only for model in requested) else \"numpy\"\n",
                                     "\n",
                                     "mf_cfg = config.get(\"mf\", {})\n",
                                     "ctrlite_cfg = config.get(\"ctrlite\", {})\n",
                                     "a2f_cfg = config.get(\"a2f\", {})\n",
                                     "ctpf_cfg = config.get(\"ctpf\", {})\n",
                                     "cdl_cfg = config.get(\"cdl\", {})\n",
                                     "hft_cfg = config.get(\"hft\", {})\n",
                                     "micm_cfg = config.get(\"micm\", {})\n",
                                     "cmcl_cfg = config.get(\"cmcl\", {})\n",
                                     "\n",
                                     "results = pipeline.train_and_evaluate_content_model(\n",
                                     "    RUN_DIR,\n",
                                     "    k_factors=16,\n",
                                     "    k_eval=[5, 10],\n",
                                     "    mf_reg=float(mf_cfg.get(\"reg\", 0.02)),\n",
                                     "    mf_iters=int(mf_cfg.get(\"iters\", 30)),\n",
                                     "    mf_lr=float(mf_cfg.get(\"lr\", 0.02)),\n",
                                     "    seed=seed,\n",
                                     "    ctrlite_reg=float(ctrlite_cfg.get(\"reg\", 0.01)),\n",
                                     "    ctrlite_lr=float(ctrlite_cfg.get(\"lr\", 0.1)),\n",
                                     "    ctrlite_iters=int(ctrlite_cfg.get(\"iters\", 80)),\n",
                                     "    adaptive=run_adaptive and model_choice == \"ctrlite\",\n",
                                     "    model=model_choice,\n",
                                     "    a2f_cfg=a2f_cfg,\n",
                                     "    ctpf_cfg=ctpf_cfg,\n",
                                     "    cdl_cfg=cdl_cfg,\n",
                                     "    hft_cfg=hft_cfg,\n",
                                     "    micm_cfg=micm_cfg,\n",
                                     "    cmcl_cfg=cmcl_cfg,\n",
                                     "    mf_cfg=mf_cfg,\n",
                                     "    backend=backend_choice,\n",
                                     "    prefer_gpu=prefer_gpu,\n",
                                     ")\n",
                                     "results\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Inspect the evaluation dictionary\n",
                                     "All reported metrics below come from the strict cold-item holdout. Use the snippet to drill into the nested dict, bucket breakdowns, and cold-only deltas.\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import json\n",
                                     "from pprint import pprint\n\n",
                                     "pprint(results)\n\n",
                                     "def _cold_summary(model_name: str, metrics: dict) -\u003e str:\n",
                                     "    keys = (\u0027hit@10\u0027, \u0027hit@20\u0027, \u0027hit@50\u0027, \u0027ndcg@10\u0027, \u0027ndcg@20\u0027, \u0027ndcg@50\u0027)\n",
                                     "    parts = []\n",
                                     "    for key in keys:\n",
                                     "        value = metrics.get(key)\n",
                                     "        if isinstance(value, (int, float)):\n",
                                     "            parts.append(f\"{key}={value:.4f}\")\n",
                                     "    return f\"{model_name}: \" + \u0027, \u0027.join(parts) if parts else f\"{model_name}: (no cold metrics)\"\n\n",
                                     "print(\u0027\\nCold-only summary (Hit/NDCG @10/20/50):\u0027)\n",
                                     "for model_name, metrics in results.items():\n",
                                     "    print(_cold_summary(model_name, metrics))\n\n",
                                     "if \u0027cmcl\u0027 in results:\n",
                                     "    bucket_snapshot = results[\u0027cmcl\u0027].get(\u0027buckets\u0027, {})\n",
                                     "    print(\u0027\\nCMCL bucket snapshot:\u0027)\n",
                                     "    print(json.dumps(bucket_snapshot, indent=2)[:2000])\n",
                                     "    delta = results[\u0027cmcl\u0027].get(\u0027delta_vs_micm\u0027)\n",
                                     "    if delta:\n",
                                     "        print(\u0027\\nDelta vs MICM:\u0027)\n",
                                     "        print(json.dumps(delta, indent=2)[:2000])\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  22,
                      "id":  "2c78965e",
                      "metadata":  {

                                   },
                      "outputs":  [
                                      {
                                          "name":  "stdout",
                                          "output_type":  "stream",
                                          "text":  [
                                                       "Loaded 80541 interactions from C:\\Users\\user\\PGMS_Rec_Systems\\PGMS_for_Recommender_Systems\\coldstart\\output\\notebook_run_20251029_223545\\warm_interactions.csv.\n",
                                                       "Dataset contains 610 unique users and 7779 unique items.\n"
                                                   ]
                                      },
                                      {
                                          "data":  {
                                                       "text/plain":  [
                                                                          "[{\u0027user_id\u0027: \u00271\u0027,\n",
                                                                          "  \u0027item_id\u0027: \u00271\u0027,\n",
                                                                          "  \u0027rating_or_y\u0027: 4.0,\n",
                                                                          "  \u0027item_text\u0027: \u0027Toy Story (1995) Adventure Animation Children Comedy Fantasy\u0027},\n",
                                                                          " {\u0027user_id\u0027: \u00271\u0027,\n",
                                                                          "  \u0027item_id\u0027: \u00273\u0027,\n",
                                                                          "  \u0027rating_or_y\u0027: 4.0,\n",
                                                                          "  \u0027item_text\u0027: \u0027Grumpier Old Men (1995) Comedy Romance\u0027},\n",
                                                                          " {\u0027user_id\u0027: \u00271\u0027,\n",
                                                                          "  \u0027item_id\u0027: \u00276\u0027,\n",
                                                                          "  \u0027rating_or_y\u0027: 4.0,\n",
                                                                          "  \u0027item_text\u0027: \u0027Heat (1995) Action Crime Thriller\u0027}]"
                                                                      ]
                                                   },
                                          "execution_count":  22,
                                          "metadata":  {

                                                       },
                                          "output_type":  "execute_result"
                                      }
                                  ],
                      "source":  [
                                     "warm_rows = data_io.load_interactions(RUN_DIR / \"warm_interactions.csv\")\n",
                                     "warm_rows[:3]\n"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  23,
                      "id":  "0e39a64f",
                      "metadata":  {

                                   },
                      "outputs":  [
                                      {
                                          "name":  "stdout",
                                          "output_type":  "stream",
                                          "text":  [
                                                       "coldstart\\output\\notebook_run_20251029_223545\\cold_interactions.csv (1239615 bytes)\n",
                                                       "coldstart\\output\\notebook_run_20251029_223545\\cold_item_ids.json (22354 bytes)\n",
                                                       "coldstart\\output\\notebook_run_20251029_223545\\cold_item_ids.txt (12626 bytes)\n",
                                                       "coldstart\\output\\notebook_run_20251029_223545\\cold_item_text_features.json (1395387 bytes)\n",
                                                       "coldstart\\output\\notebook_run_20251029_223545\\models\\U.json (92740 bytes)\n",
                                                       "coldstart\\output\\notebook_run_20251029_223545\\models\\V_warm.json (1182263 bytes)\n",
                                                       "coldstart\\output\\notebook_run_20251029_223545\\tfidf_state.json (6049 bytes)\n",
                                                       "coldstart\\output\\notebook_run_20251029_223545\\warm_interactions.csv (4871313 bytes)\n",
                                                       "coldstart\\output\\notebook_run_20251029_223545\\warm_item_ids.json (89748 bytes)\n",
                                                       "coldstart\\output\\notebook_run_20251029_223545\\warm_item_text_features.json (5591572 bytes)\n"
                                                   ]
                                      }
                                  ],
                      "source":  [
                                     "for path in sorted(RUN_DIR.rglob(\"*\")):\n",
                                     "    if path.is_file():\n",
                                     "        rel_path = path.relative_to(PROJECT_ROOT)\n",
                                     "        size = path.stat().st_size\n",
                                     "        print(f\"{rel_path} ({size} bytes)\")\n"
                                 ]
                  }
              ],
    "metadata":  {
                     "kernelspec":  {
                                        "display_name":  "Python 3",
                                        "language":  "python",
                                        "name":  "python3"
                                    },
                     "language_info":  {
                                           "codemirror_mode":  {
                                                                   "name":  "ipython",
                                                                   "version":  3
                                                               },
                                           "file_extension":  ".py",
                                           "mimetype":  "text/x-python",
                                           "name":  "python",
                                           "nbconvert_exporter":  "python",
                                           "pygments_lexer":  "ipython3",
                                           "version":  "3.13.7"
                                       }
                 },
    "nbformat":  4,
    "nbformat_minor":  5
}
