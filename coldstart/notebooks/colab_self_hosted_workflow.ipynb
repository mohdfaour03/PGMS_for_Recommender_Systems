{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd78ea7e",
   "metadata": {},
   "source": [
    "\n",
    "# Cold-Start Recommender: Colab Workflow\n",
    "\n",
    "This notebook clones the project, downloads the configured dataset (MovieLens, Amazon, or Goodreads), prepares strict new-item splits with leakage-safe text encoders, and trains the classical baselines plus CMCL with GPU acceleration (if available). Upload only this notebook to Colab, run the cells from top to bottom, and you will get a full benchmark with pseudo-exposure modeling and counterfactual evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROJECT_URL = \"https://github.com/mohdfaour03/PGMS_for_Recommender_Systems.git\"\n",
    "PROJECT_ROOT = Path(\"/content/PGMS_for_Recommender_Systems\")\n",
    "\n",
    "if not PROJECT_ROOT.exists():\n",
    "    !git clone $PROJECT_URL $PROJECT_ROOT\n",
    "else:\n",
    "    print(f\"Repository already present at {PROJECT_ROOT}\")\n",
    "\n",
    "%cd /content/PGMS_for_Recommender_Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9174884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "def locate_project_root() -> Path:\n",
    "    current = Path.cwd().resolve()\n",
    "    for candidate in (current, *current.parents):\n",
    "        if (candidate / \"coldstart\" / \"src\").exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\"Cannot locate project root containing 'coldstart/src'.\")\n",
    "\n",
    "\n",
    "PROJECT_ROOT = locate_project_root()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from coldstart.src.notebook_utils import (\n",
    "    _read_simple_yaml,\n",
    "    build_amazon_interaction_frame,\n",
    "    build_goodreads_interaction_frame,\n",
    "    build_interaction_frame,\n",
    "    GOODREADS_GENRES,\n",
    ")\n",
    "from coldstart.src import data_io, pipeline\n",
    "\n",
    "DATA_SOURCE = \"goodreads\"  # options: 'movielens', 'amazon', 'goodreads'\n",
    "DATASET_VARIANT = \"small\"  # only used for MovieLens\n",
    "AMAZON_VARIANT = \"beauty\"  # only used when DATA_SOURCE == 'amazon'\n",
    "GOODREADS_VARIANT = \"poetry\"  # change to any entry from GOODREADS_GENRES\n",
    "DATA_DIR = PROJECT_ROOT / \"coldstart\" / \"data\"\n",
    "if DATA_SOURCE == \"amazon\":\n",
    "    DATA_PATH = DATA_DIR / f\"amazon_{AMAZON_VARIANT}.csv\"\n",
    "elif DATA_SOURCE == \"goodreads\":\n",
    "    DATA_PATH = DATA_DIR / f\"goodreads_{GOODREADS_VARIANT}.csv\"\n",
    "else:\n",
    "    DATA_PATH = DATA_DIR / f\"movielens_latest_{DATASET_VARIANT}.csv\"\n",
    "CONFIG_PATH = PROJECT_ROOT / \"coldstart\" / \"configs\" / \"base.yaml\"\n",
    "OUTPUT_ROOT = PROJECT_ROOT / \"coldstart\" / \"output\"\n",
    "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    if DATA_SOURCE == \"amazon\":\n",
    "        df = build_amazon_interaction_frame(dataset=AMAZON_VARIANT, cache_dir=DATA_DIR)\n",
    "        source_name = f\"Amazon {AMAZON_VARIANT}\"\n",
    "    elif DATA_SOURCE == \"goodreads\":\n",
    "        df = build_goodreads_interaction_frame(genre=GOODREADS_VARIANT, cache_dir=DATA_DIR)\n",
    "        source_name = f\"Goodreads {GOODREADS_VARIANT}\"\n",
    "    else:\n",
    "        df = build_interaction_frame(dataset=DATASET_VARIANT)\n",
    "        source_name = f\"MovieLens {DATASET_VARIANT}\"\n",
    "    df.to_csv(DATA_PATH, index=False)\n",
    "    print(f\"Downloaded {source_name} interactions to {DATA_PATH}\")\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_DIR = OUTPUT_ROOT / f\"notebook_run_{timestamp}\"\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH, RUN_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ed48a",
   "metadata": {},
   "source": [
    "## Configure the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b185706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "CONFIG_PATH = PROJECT_ROOT / \"coldstart\" / \"configs\" / \"base.yaml\"\n",
    "config = _read_simple_yaml(CONFIG_PATH)\n",
    "\n",
    "# --- User-tunable parameters ---\n",
    "INTERACTION_LIMIT_OVERRIDE = 180_000  # set to None to use the per-source default\n",
    "cold_item_frac = 0.2\n",
    "seed = 42\n",
    "prefer_gpu = True\n",
    "\n",
    "k_factors = 16\n",
    "k_eval = [10, 20, 50]\n",
    "\n",
    "default_limits = {\n",
    "    \"goodreads\": 180_000,\n",
    "    \"amazon\": 600_000,\n",
    "    \"movielens\": 1_200_000,\n",
    "}\n",
    "interaction_limit = (\n",
    "    INTERACTION_LIMIT_OVERRIDE\n",
    "    if INTERACTION_LIMIT_OVERRIDE is not None\n",
    "    else default_limits.get(DATA_SOURCE)\n",
    ")\n",
    "\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Run directory: {RUN_DIR}\")\n",
    "if interaction_limit:\n",
    "    print(f\"Capping prepare_dataset to {interaction_limit:,} interactions to conserve RAM.\")\n",
    "else:\n",
    "    print(\"Using full dataset (interaction_limit=None). Override above if RAM becomes an issue.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce159373",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(\"Dataset missing. Re-run the setup cell above to download it.\")\n",
    "\n",
    "size_mb = DATA_PATH.stat().st_size / 1e6\n",
    "print(f\"Dataset already present at {DATA_PATH} (~{size_mb:.1f} MB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b81659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_params = config.get('tfidf', {})\n",
    "text_encoder_cfg = config.get('text_encoder', {})\n",
    "encoder_type = text_encoder_cfg.get('type', 'tfidf')\n",
    "encoder_params = text_encoder_cfg.get('params')\n",
    "if encoder_type == 'frozen_bert_linear':\n",
    "    encoder_params = dict(encoder_params or {})\n",
    "    encoder_params.setdefault(\"model_name\", \"distilbert-base-uncased\")\n",
    "    encoder_params[\"model_name\"] = \"distilbert-base-uncased\"\n",
    "    current_max_len = int(encoder_params.get(\"max_length\", 128) or 128)\n",
    "    encoder_params[\"max_length\"] = min(128, current_max_len)\n",
    "if encoder_params is None and encoder_type == 'tfidf':\n",
    "    encoder_params = tfidf_params\n",
    "\n",
    "prepare_limit = interaction_limit if interaction_limit else None\n",
    "val_item_frac = float(config.get('prepare', {}).get('val_item_frac', 0) or 0)\n",
    "val_item_frac = val_item_frac if val_item_frac > 0 else None\n",
    "\n",
    "pipeline.prepare_dataset(\n",
    "    DATA_PATH,\n",
    "    RUN_DIR,\n",
    "    tfidf_params=tfidf_params,\n",
    "    encoder_type=encoder_type,\n",
    "    encoder_params=encoder_params,\n",
    "    cold_item_frac=cold_item_frac,\n",
    "    val_item_frac=val_item_frac,\n",
    "    seed=seed,\n",
    "    interaction_limit=prepare_limit,\n",
    ")\n",
    "\n",
    "sorted(path.name for path in RUN_DIR.iterdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "\n",
    "cmcl_cfg = copy.deepcopy(dict(config.get(\"cmcl\", {})))\n",
    "exposure_cfg = dict(cmcl_cfg.get(\"exposure\", {}) or {})\n",
    "hard_neg_cfg = dict(cmcl_cfg.get(\"hard_negatives\", {}) or {})\n",
    "exposure_limit = 350_000\n",
    "if exposure_cfg.get(\"max_training_samples\") in (None, \"\", 0):\n",
    "    exposure_cfg[\"max_training_samples\"] = exposure_limit\n",
    "cmcl_cfg[\"exposure\"] = exposure_cfg\n",
    "cmcl_cfg.setdefault(\"sampled_negatives\", 512)\n",
    "cmcl_cfg.setdefault(\"max_weight\", 10.0)\n",
    "\n",
    "core_keys = [\n",
    "    \"lr\",\n",
    "    \"reg\",\n",
    "    \"iters\",\n",
    "    \"batch_size\",\n",
    "    \"temperature\",\n",
    "    \"self_normalize\",\n",
    "    \"max_positives\",\n",
    "    \"pi_floor\",\n",
    "    \"max_weight\",\n",
    "    \"sampled_negatives\",\n",
    "]\n",
    "print(\"[cmcl] core settings:\")\n",
    "for key in core_keys:\n",
    "    value = cmcl_cfg.get(key, \"<default>\")\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"[cmcl] exposure estimator:\")\n",
    "if exposure_cfg:\n",
    "    for key, value in exposure_cfg.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"  (using defaults)\")\n",
    "print(\"[cmcl] hard negatives:\")\n",
    "if hard_neg_cfg.get(\"k\", 0) > 0:\n",
    "    print(f\"  k={hard_neg_cfg.get('k')} min_sim={hard_neg_cfg.get('min_sim')}\")\n",
    "else:\n",
    "    print(\"  disabled (k=0)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab24337",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "\n",
    "mf_cfg = config.get('mf', {})\n",
    "ctrlite_cfg = config.get('ctrlite', {})\n",
    "a2f_cfg = config.get('a2f', {})\n",
    "ctpf_cfg = config.get('ctpf', {})\n",
    "cdl_cfg = config.get('cdl', {})\n",
    "hft_cfg = config.get('hft', {})\n",
    "cmcl_cfg_main = copy.deepcopy(cmcl_cfg)\n",
    "\n",
    "mf_runtime_cfg = {\n",
    "    'batch_size': 8192,\n",
    "    'score_batch_size': 8192,\n",
    "    'infer_batch_size': 8192,\n",
    "    'ctrlite_batch_size': 4096,\n",
    "}\n",
    "\n",
    "results = pipeline.train_and_evaluate_content_model(\n",
    "    RUN_DIR,\n",
    "    k_factors=k_factors,\n",
    "    k_eval=k_eval,\n",
    "    mf_reg=float(mf_cfg.get('reg', 0.02)),\n",
    "    mf_iters=int(mf_cfg.get('iters', 30)),\n",
    "    mf_lr=float(mf_cfg.get('lr', 0.02)),\n",
    "    seed=seed,\n",
    "    ctrlite_reg=float(ctrlite_cfg.get('reg', 0.01)),\n",
    "    ctrlite_lr=float(ctrlite_cfg.get('lr', 0.1)),\n",
    "    ctrlite_iters=int(ctrlite_cfg.get('iters', 80)),\n",
    "    model='ctrlite,a2f,ctpf,cdl,hft,cmcl',\n",
    "    a2f_cfg=a2f_cfg,\n",
    "    ctpf_cfg=ctpf_cfg,\n",
    "    cdl_cfg=cdl_cfg,\n",
    "    hft_cfg=hft_cfg,\n",
    "    cmcl_cfg=cmcl_cfg_main,\n",
    "    backend='torch',\n",
    "    prefer_gpu=prefer_gpu,\n",
    "    mf_cfg=mf_runtime_cfg,\n",
    ")\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d857ac",
   "metadata": {},
   "source": [
    "### CMCL ablations\n",
    "Run targeted CMCL sweeps to measure the impact of IPS weighting and exposure-conditioned negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c1527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "\n",
    "def _deep_update(base: dict, patch: dict) -> dict:\n",
    "    for key, value in (patch or {}).items():\n",
    "        if isinstance(value, dict):\n",
    "            existing = base.get(key, {})\n",
    "            if not isinstance(existing, dict):\n",
    "                existing = {}\n",
    "            base[key] = _deep_update(existing, value)\n",
    "        else:\n",
    "            base[key] = value\n",
    "    return base\n",
    "\n",
    "\n",
    "def run_cmcl_variant(label: str, overrides: dict):\n",
    "    variant_cfg = _deep_update(copy.deepcopy(cmcl_cfg), overrides or {})\n",
    "    print(f\"[cmcl ablation] running {label} with overrides: {overrides}\")\n",
    "    variant_results = pipeline.train_and_evaluate_content_model(\n",
    "        RUN_DIR,\n",
    "        k_factors=k_factors,\n",
    "        k_eval=k_eval,\n",
    "        mf_reg=float(mf_cfg.get('reg', 0.02)),\n",
    "        mf_iters=int(mf_cfg.get('iters', 30)),\n",
    "        mf_lr=float(mf_cfg.get('lr', 0.02)),\n",
    "        seed=seed,\n",
    "        ctrlite_reg=float(ctrlite_cfg.get('reg', 0.01)),\n",
    "        ctrlite_lr=float(ctrlite_cfg.get('lr', 0.1)),\n",
    "        ctrlite_iters=int(ctrlite_cfg.get('iters', 80)),\n",
    "        model='cmcl',\n",
    "        a2f_cfg=a2f_cfg,\n",
    "        ctpf_cfg=ctpf_cfg,\n",
    "        cdl_cfg=cdl_cfg,\n",
    "        hft_cfg=hft_cfg,\n",
    "        cmcl_cfg=variant_cfg,\n",
    "        backend='torch',\n",
    "        prefer_gpu=prefer_gpu,\n",
    "        mf_cfg=mf_runtime_cfg,\n",
    "    )\n",
    "    metrics = variant_results.get('cmcl') if isinstance(variant_results, dict) else variant_results\n",
    "    if isinstance(metrics, dict):\n",
    "        hit = metrics.get('hit@10')\n",
    "        ndcg = metrics.get('ndcg@10')\n",
    "        print(f\"[cmcl ablation] {label} hit@10={hit:.4f} ndcg@10={ndcg:.4f}\")\n",
    "    return variant_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6756490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmcl_no_ips_results = run_cmcl_variant(\n",
    "    \"no_ips_weights\",\n",
    "    {\n",
    "        \"self_normalize\": False,\n",
    "        \"max_weight\": 1.0,\n",
    "        \"pi_floor\": 1.0,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c38a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmcl_random_neg_results = run_cmcl_variant(\n",
    "    \"random_negatives\",\n",
    "    {\n",
    "        \"sampled_negatives\": 0,\n",
    "        \"hard_negatives\": {\"k\": 0},\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01324760",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in sorted(RUN_DIR.rglob(\"*\")):\n",
    "    if path.is_file():\n",
    "        rel = path.relative_to(PROJECT_ROOT)\n",
    "        size_kb = path.stat().st_size / 1024\n",
    "        print(f\"{rel} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b537ccc9",
   "metadata": {},
   "source": [
    "## Inspect metrics and buckets\n",
    "Colab runs can print the nested evaluation dictionary (with confidence intervals, per-bucket metrics, and `buckets`) using the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1764b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(results)\n",
    "if 'cmcl' in results:\n",
    "    print('CMCL bucket snapshot:')\n",
    "    print(json.dumps(results['cmcl'].get('buckets', {}), indent=2)[:2000])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
