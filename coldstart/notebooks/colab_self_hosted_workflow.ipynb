{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc3a8a5",
   "metadata": {},
   "source": [
    "# Cold-Start Recommender: Colab Workflow\n",
    "\n",
    "Run the cells in order to clone the PGMS cold-start benchmark, download the requested dataset (MovieLens, Amazon, Goodreads, or Microsoft News), prepare leakage-safe warm/cold splits, and train every baseline plus CMCL (default + ablations). Upload only this notebook to Colab; it will set up everything inside `/content/PGMS_for_Recommender_Systems` and save artifacts under `coldstart/output/notebook_run_*`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROJECT_URL = \"https://github.com/mohdfaour03/PGMS_for_Recommender_Systems.git\"\n",
    "PROJECT_ROOT = Path(\"/content/PGMS_for_Recommender_Systems\")\n",
    "\n",
    "if not PROJECT_ROOT.exists():\n",
    "    !git clone $PROJECT_URL $PROJECT_ROOT\n",
    "else:\n",
    "    print(f\"Repository already present at {PROJECT_ROOT}\")\n",
    "\n",
    "%cd /content/PGMS_for_Recommender_Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9c08ad",
   "metadata": {},
   "source": [
    "## Configure the run\n",
    "Choose the source dataset (MovieLens, Amazon, or Goodreads), adjust the interaction cap if you need to conserve RAM, and set the random seed / evaluation cutoffs. The cell below also locates the project root inside Colab and loads the YAML defaults."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68d221",
   "metadata": {},
   "source": [
    "> **Heads up (Microsoft News)**: the MIND dataset requires accepting Microsoft's license. If you set `DATA_SOURCE = \"msnews\"`, download the requested zip (e.g., `MINDsmall_train.zip`) from [msnews.github.io](https://msnews.github.io/) and place it under `coldstart/data/` before running the setup cell. The notebook will reuse the local file and extract it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b32bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "def locate_project_root() -> Path:\n",
    "    current = Path.cwd().resolve()\n",
    "    for candidate in (current, *current.parents):\n",
    "        if (candidate / \"coldstart\" / \"src\").exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\"Cannot locate project root containing 'coldstart/src'.\")\n",
    "\n",
    "\n",
    "PROJECT_ROOT = locate_project_root()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from coldstart.src.notebook_utils import (\n",
    "    _read_simple_yaml,\n",
    "    build_amazon_interaction_frame,\n",
    "    build_goodreads_interaction_frame,\n",
    "    build_interaction_frame,\n",
    "    build_msnews_interaction_frame,\n",
    "    GOODREADS_GENRES,\n",
    "    MSNEWS_VARIANTS,\n",
    ")\n",
    "from coldstart.src import data_io, pipeline\n",
    "\n",
    "DATA_SOURCE = \"movielens\"  # options: 'movielens', 'amazon', 'goodreads', 'msnews'\n",
    "DATASET_VARIANT = \"medium\"  # MovieLens-only\n",
    "AMAZON_VARIANT = \"beauty\"\n",
    "GOODREADS_VARIANT = \"poetry\"  # any entry from GOODREADS_GENRES\n",
    "MSNEWS_VARIANT = \"mind_small_train\"  # any entry from MSNEWS_VARIANTS\n",
    "\n",
    "INTERACTION_LIMIT_OVERRIDE = 180_000  # set to None to use the per-source default\n",
    "cold_item_frac = 0.2\n",
    "seed = 42\n",
    "prefer_gpu = True\n",
    "\n",
    "k_factors = 16\n",
    "k_eval = [10, 20, 50]\n",
    "\n",
    "default_limits = {\n",
    "    \"goodreads\": 180_000,\n",
    "    \"amazon\": 600_000,\n",
    "    \"movielens\": 1_200_000,\n",
    "    \"msnews\": 800_000,\n",
    "}\n",
    "interaction_limit = (\n",
    "    INTERACTION_LIMIT_OVERRIDE\n",
    "    if INTERACTION_LIMIT_OVERRIDE is not None\n",
    "    else default_limits.get(DATA_SOURCE)\n",
    ")\n",
    "# Let MSNews use the full split by default; override above if you truly need a cap.\n",
    "if DATA_SOURCE == \"msnews\" and INTERACTION_LIMIT_OVERRIDE is not None:\n",
    "    interaction_limit = None\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"coldstart\" / \"data\"\n",
    "if DATA_SOURCE == \"amazon\":\n",
    "    DATA_PATH = DATA_DIR / f\"amazon_{AMAZON_VARIANT}.csv\"\n",
    "elif DATA_SOURCE == \"goodreads\":\n",
    "    DATA_PATH = DATA_DIR / f\"goodreads_{GOODREADS_VARIANT}.csv\"\n",
    "elif DATA_SOURCE == \"msnews\":\n",
    "    DATA_PATH = DATA_DIR / f\"msnews_{MSNEWS_VARIANT}.csv\"\n",
    "else:\n",
    "    DATA_PATH = DATA_DIR / f\"movielens_latest_{DATASET_VARIANT}.csv\"\n",
    "\n",
    "CONFIG_PATH = PROJECT_ROOT / \"coldstart\" / \"configs\" / \"base.yaml\"\n",
    "config = _read_simple_yaml(CONFIG_PATH)\n",
    "\n",
    "OUTPUT_ROOT = PROJECT_ROOT / \"coldstart\" / \"output\"\n",
    "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_DIR = OUTPUT_ROOT / f\"notebook_run_{timestamp}\"\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Run directory: {RUN_DIR}\")\n",
    "if interaction_limit:\n",
    "    print(f\"Capping prepare_dataset to {interaction_limit:,} interactions to conserve RAM.\")\n",
    "else:\n",
    "    print(\"Using full dataset (interaction_limit=None). Override above if RAM becomes an issue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c097d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_PATH.exists():\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    if DATA_SOURCE == \"amazon\":\n",
    "        df = build_amazon_interaction_frame(dataset=AMAZON_VARIANT, cache_dir=DATA_DIR)\n",
    "        source_name = f\"Amazon {AMAZON_VARIANT}\"\n",
    "    elif DATA_SOURCE == \"goodreads\":\n",
    "        df = build_goodreads_interaction_frame(genre=GOODREADS_VARIANT, cache_dir=DATA_DIR)\n",
    "        source_name = f\"Goodreads {GOODREADS_VARIANT}\"\n",
    "    elif DATA_SOURCE == \"msnews\":\n",
    "        df = build_msnews_interaction_frame(variant=MSNEWS_VARIANT, cache_dir=DATA_DIR)\n",
    "        source_name = f\"MSNews {MSNEWS_VARIANT}\"\n",
    "    else:\n",
    "        df = build_interaction_frame(dataset=DATASET_VARIANT)\n",
    "        source_name = f\"MovieLens {DATASET_VARIANT}\"\n",
    "    df.to_csv(DATA_PATH, index=False)\n",
    "    print(f\"Downloaded {source_name} interactions to {DATA_PATH}\")\n",
    "else:\n",
    "    size_mb = DATA_PATH.stat().st_size / 1e6\n",
    "    print(f\"Dataset already present at {DATA_PATH} (~{size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b2a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_params = config.get('tfidf', {})\n",
    "text_encoder_cfg = config.get('text_encoder', {})\n",
    "encoder_type = text_encoder_cfg.get('type', 'tfidf')\n",
    "encoder_params = text_encoder_cfg.get('params')\n",
    "if encoder_params is None and encoder_type == 'tfidf':\n",
    "    encoder_params = tfidf_params\n",
    "\n",
    "# MSNews benefits from more text capacity; bump tfidf dims and disable interaction cap.\n",
    "if DATA_SOURCE == \"msnews\":\n",
    "    tfidf_params_local = dict(tfidf_params)\n",
    "    tfidf_params_local['max_features'] = max(tfidf_params_local.get('max_features', 0) or 0, 5000)\n",
    "else:\n",
    "    tfidf_params_local = tfidf_params\n",
    "\n",
    "prepare_limit = interaction_limit if interaction_limit else None\n",
    "val_item_frac = float(config.get('prepare', {}).get('val_item_frac', 0) or 0)\n",
    "val_item_frac = val_item_frac if val_item_frac > 0 else None\n",
    "\n",
    "pipeline.prepare_dataset(\n",
    "    DATA_PATH,\n",
    "    RUN_DIR,\n",
    "    tfidf_params=tfidf_params_local,\n",
    "    encoder_type=encoder_type,\n",
    "    encoder_params=encoder_params if DATA_SOURCE != \"msnews\" else tfidf_params_local,\n",
    "    cold_item_frac=cold_item_frac,\n",
    "    val_item_frac=val_item_frac,\n",
    "    seed=seed,\n",
    "    interaction_limit=prepare_limit,\n",
    ")\n",
    "\n",
    "sorted_outputs = sorted(path.name for path in RUN_DIR.iterdir())\n",
    "sorted_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e54dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "cmcl_cfg = copy.deepcopy(dict(config.get('cmcl', {})))\n",
    "exposure_cfg = dict(cmcl_cfg.get('exposure', {}) or {})\n",
    "exposure_limit = 350_000\n",
    "if exposure_cfg.get('max_training_samples') in (None, '', 0):\n",
    "    exposure_cfg['max_training_samples'] = exposure_limit\n",
    "cmcl_cfg['exposure'] = exposure_cfg\n",
    "\n",
    "hard_neg_cfg = dict(cmcl_cfg.get('hard_negatives', {}) or {})\n",
    "cmcl_cfg['hard_negatives'] = hard_neg_cfg\n",
    "\n",
    "# For MSNews, give CMCL more capacity/steps.\n",
    "if DATA_SOURCE == \"msnews\":\n",
    "    cmcl_cfg['iters'] = max(int(cmcl_cfg.get('iters', 60)), 120)\n",
    "    cmcl_cfg['batch_size'] = max(int(cmcl_cfg.get('batch_size', 128)), 256)\n",
    "\n",
    "print('[cmcl] core settings:')\n",
    "for key in (\n",
    "    'lr',\n",
    "    'reg',\n",
    "    'iters',\n",
    "    'batch_size',\n",
    "    'temperature',\n",
    "    'self_normalize',\n",
    "    'max_positives',\n",
    "    'pi_floor',\n",
    "    'max_weight',\n",
    "):\n",
    "    value = cmcl_cfg.get(key)\n",
    "    if value is not None:\n",
    "        print(f\"  {key}: {value}\")\n",
    "print('[cmcl] exposure estimator:')\n",
    "for key, value in cmcl_cfg['exposure'].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "if hard_neg_cfg.get('k', 0):\n",
    "    print('[cmcl] hard negatives:')\n",
    "    for key, value in hard_neg_cfg.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print('[cmcl] hard negatives: disabled (k=0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64842814",
   "metadata": {},
   "source": [
    "## Train classical baselines\n",
    "This block fits the matrix-factorization family (Ctrlite, A2F, CTPF, CDL, and HFT) with the prepared splits. CMCL is run separately so we can highlight its contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae8201",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_cfg = config.get('mf', {})\n",
    "ctrlite_cfg = config.get('ctrlite', {})\n",
    "a2f_cfg = config.get('a2f', {})\n",
    "ctpf_cfg = config.get('ctpf', {})\n",
    "cdl_cfg = config.get('cdl', {})\n",
    "hft_cfg = config.get('hft', {})\n",
    "\n",
    "mf_runtime_cfg = {\n",
    "    'batch_size': 8192,\n",
    "    'score_batch_size': 8192,\n",
    "    'infer_batch_size': 8192,\n",
    "    'ctrlite_batch_size': 4096,\n",
    "}\n",
    "\n",
    "results = pipeline.train_and_evaluate_content_model(\n",
    "    RUN_DIR,\n",
    "    k_factors=k_factors,\n",
    "    k_eval=k_eval,\n",
    "    mf_reg=float(mf_cfg.get('reg', 0.02)),\n",
    "    mf_iters=int(mf_cfg.get('iters', 30)),\n",
    "    mf_lr=float(mf_cfg.get('lr', 0.02)),\n",
    "    seed=seed,\n",
    "    ctrlite_reg=float(ctrlite_cfg.get('reg', 0.01)),\n",
    "    ctrlite_lr=float(ctrlite_cfg.get('lr', 0.1)),\n",
    "    ctrlite_iters=int(ctrlite_cfg.get('iters', 80)),\n",
    "    model='ctrlite,a2f,ctpf,cdl,hft',\n",
    "    a2f_cfg=a2f_cfg,\n",
    "    ctpf_cfg=ctpf_cfg,\n",
    "    cdl_cfg=cdl_cfg,\n",
    "    hft_cfg=hft_cfg,\n",
    "    cmcl_cfg=cmcl_cfg,\n",
    "    backend='torch',\n",
    "    prefer_gpu=prefer_gpu,\n",
    "    mf_cfg=mf_runtime_cfg,\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfb3292",
   "metadata": {},
   "source": [
    "## CMCL defaults and ablations\n",
    "Define a helper to run CMCL with different overrides so we can log the headline model (default) plus the `no_ips_weights` and `random_negatives` ablations mentioned in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3709d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _deep_update(base: dict, patch: dict) -> dict:\n",
    "    for key, value in (patch or {}).items():\n",
    "        if isinstance(value, dict):\n",
    "            existing = base.get(key, {})\n",
    "            if not isinstance(existing, dict):\n",
    "                existing = {}\n",
    "            base[key] = _deep_update(existing, value)\n",
    "        else:\n",
    "            base[key] = value\n",
    "    return base\n",
    "\n",
    "\n",
    "def run_cmcl_variant(label: str, overrides: dict):\n",
    "    variant_cfg = _deep_update(copy.deepcopy(cmcl_cfg), overrides or {})\n",
    "    print(f\"[cmcl] running {label} with overrides: {overrides}\")\n",
    "    variant_results = pipeline.train_and_evaluate_content_model(\n",
    "        RUN_DIR,\n",
    "        k_factors=k_factors,\n",
    "        k_eval=k_eval,\n",
    "        mf_reg=float(mf_cfg.get('reg', 0.02)),\n",
    "        mf_iters=int(mf_cfg.get('iters', 30)),\n",
    "        mf_lr=float(mf_cfg.get('lr', 0.02)),\n",
    "        seed=seed,\n",
    "        ctrlite_reg=float(ctrlite_cfg.get('reg', 0.01)),\n",
    "        ctrlite_lr=float(ctrlite_cfg.get('lr', 0.1)),\n",
    "        ctrlite_iters=int(ctrlite_cfg.get('iters', 80)),\n",
    "        model='cmcl',\n",
    "        a2f_cfg=a2f_cfg,\n",
    "        ctpf_cfg=ctpf_cfg,\n",
    "        cdl_cfg=cdl_cfg,\n",
    "        hft_cfg=hft_cfg,\n",
    "        cmcl_cfg=variant_cfg,\n",
    "        backend='torch',\n",
    "        prefer_gpu=prefer_gpu,\n",
    "        mf_cfg=mf_runtime_cfg,\n",
    "    )\n",
    "    metrics = variant_results.get('cmcl') if isinstance(variant_results, dict) else variant_results\n",
    "    if isinstance(metrics, dict):\n",
    "        hit = metrics.get('hit@10')\n",
    "        ndcg = metrics.get('ndcg@10')\n",
    "        if hit is not None and ndcg is not None:\n",
    "            print(f\"[cmcl] {label} hit@10={hit:.4f} ndcg@10={ndcg:.4f}\")\n",
    "    results[f\"cmcl_{label}\"] = metrics\n",
    "    return variant_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmcl_default_results = run_cmcl_variant('default', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f7abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmcl_no_ips_results = run_cmcl_variant(\n",
    "    'no_ips_weights',\n",
    "    {\n",
    "        'self_normalize': False,\n",
    "        'max_weight': 1.0,\n",
    "        'pi_floor': 1.0,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e30c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmcl_random_neg_results = run_cmcl_variant(\n",
    "    'random_negatives',\n",
    "    {\n",
    "        'hard_negatives': {\n",
    "            'k': 0,\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9dc6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in sorted(RUN_DIR.rglob(\"*\")):\n",
    "    if path.is_file():\n",
    "        rel = path.relative_to(PROJECT_ROOT)\n",
    "        size_kb = path.stat().st_size / 1024\n",
    "        print(f\"{rel} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456eab02",
   "metadata": {},
   "source": [
    "## Inspect metrics and buckets\n",
    "Print the nested evaluation dictionary (with confidence intervals, per-bucket metrics, and CMCL variants) using the next cell. Bucket dumps are truncated to keep the Colab log readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(results)\n",
    "for key, metrics in results.items():\n",
    "    if key == 'cmcl' or key.startswith('cmcl_'):\n",
    "        if isinstance(metrics, dict):\n",
    "            print(f\"\n",
    "{key} bucket snapshot:\")\n",
    "            print(json.dumps(metrics.get('buckets', {}), indent=2)[:2000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
