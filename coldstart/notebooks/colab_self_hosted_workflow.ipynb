{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fd78ea7e",
      "metadata": {},
      "source": [
        "# Cold-Start Recommender: Colab Workflow\n",
        "\n",
        "This notebook clones the project, downloads MovieLens interactions, prepares the strict new-item splits (with leakage-safe text encoders), and trains all baselines plus MICM/CMCL with GPU acceleration (if available). Upload only this notebook to Colab, run the cells from top to bottom, and you will get a full medium-dataset benchmark with pseudo-exposure modeling and counterfactual evaluation metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a323522d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "PROJECT_URL = \"https://github.com/mohdfaour03/PGMS_for_Recommender_Systems.git\"\n",
        "PROJECT_ROOT = Path(\"/content/PGMS_for_Recommender_Systems\")\n",
        "\n",
        "if not PROJECT_ROOT.exists():\n",
        "    !git clone $PROJECT_URL $PROJECT_ROOT\n",
        "else:\n",
        "    print(f\"Repository already present at {PROJECT_ROOT}\")\n",
        "\n",
        "%cd /content/PGMS_for_Recommender_Systems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9174884",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/PGMS_for_Recommender_Systems\").resolve()\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "from coldstart.src.notebook_utils import build_interaction_frame, _read_simple_yaml\n",
        "from coldstart.src import data_io, pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "067ed48a",
      "metadata": {},
      "source": [
        "## Configure the run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b185706",
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "CONFIG_PATH = PROJECT_ROOT / 'coldstart' / 'configs' / 'base.yaml'\n",
        "config = _read_simple_yaml(CONFIG_PATH)\n",
        "\n",
        "# --- User-tunable parameters ---\n",
        "dataset = 'medium'          # 'small' or 'medium'\n",
        "interaction_limit = 300000   # set to None for full dataset\n",
        "cold_item_frac = 0.2\n",
        "seed = 42\n",
        "prefer_gpu = True\n",
        "\n",
        "k_factors = 16\n",
        "k_eval = [10, 20, 50]\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'coldstart' / 'data'\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "DATA_PATH = DATA_DIR / f\"movielens_latest_{dataset}.csv\"\n",
        "\n",
        "OUTPUT_ROOT = PROJECT_ROOT / 'coldstart' / 'output_colab'\n",
        "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "RUN_DIR = OUTPUT_ROOT / f\"colab_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Data path: {DATA_PATH}\")\n",
        "print(f\"Run directory: {RUN_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce159373",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not DATA_PATH.exists():\n",
        "    print(f\"Downloading MovieLens '{dataset}' interactions...\")\n",
        "    frame = build_interaction_frame(dataset=dataset, limit=interaction_limit)\n",
        "    frame.to_csv(DATA_PATH, index=False)\n",
        "    print(f\"Saved dataset to {DATA_PATH}\")\n",
        "else:\n",
        "    print(f\"Dataset already present at {DATA_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b81659a",
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_params = config.get('tfidf', {})\n",
        "text_encoder_cfg = config.get('text_encoder', {})\n",
        "encoder_type = text_encoder_cfg.get('type', 'tfidf')\n",
        "encoder_params = text_encoder_cfg.get('params')\n",
        "if encoder_params is None and encoder_type == 'tfidf':\n",
        "    encoder_params = tfidf_params\n",
        "\n",
        "prepare_limit = interaction_limit if interaction_limit else None\n",
        "val_item_frac = float(config.get('prepare', {}).get('val_item_frac', 0) or 0)\n",
        "val_item_frac = val_item_frac if val_item_frac > 0 else None\n",
        "\n",
        "pipeline.prepare_dataset(\n",
        "    DATA_PATH,\n",
        "    RUN_DIR,\n",
        "    tfidf_params=tfidf_params,\n",
        "    encoder_type=encoder_type,\n",
        "    encoder_params=encoder_params,\n",
        "    cold_item_frac=cold_item_frac,\n",
        "    val_item_frac=val_item_frac,\n",
        "    seed=seed,\n",
        "    interaction_limit=prepare_limit,\n",
        ")\n",
        "\n",
        "sorted(path.name for path in RUN_DIR.iterdir())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aab24337",
      "metadata": {},
      "outputs": [],
      "source": [
        "mf_cfg = config.get('mf', {})\n",
        "ctrlite_cfg = config.get('ctrlite', {})\n",
        "a2f_cfg = config.get('a2f', {})\n",
        "ctpf_cfg = config.get('ctpf', {})\n",
        "cdl_cfg = config.get('cdl', {})\n",
        "hft_cfg = config.get('hft', {})\n",
        "micm_cfg = dict(config.get('micm', {}))\n",
        "cmcl_cfg = config.get('cmcl', {})\n",
        "\n",
        "# Optional MICM overrides for the InfoNCE mapper\n",
        "micm_cfg.update({\n",
        "    'temperature': 0.03,\n",
        "    'iters': 600,\n",
        "    'batch_size': 2048,\n",
        "    'lr': 1.5e-3,\n",
        "    'symmetric': False,\n",
        "})\n",
        "\n",
        "mf_runtime_cfg = {\n",
        "    'batch_size': 8192,\n",
        "    'score_batch_size': 8192,\n",
        "    'infer_batch_size': 8192,\n",
        "    'ctrlite_batch_size': 4096,\n",
        "}\n",
        "\n",
        "results = pipeline.train_and_evaluate_content_model(\n",
        "    RUN_DIR,\n",
        "    k_factors=k_factors,\n",
        "    k_eval=k_eval,\n",
        "    mf_reg=float(mf_cfg.get('reg', 0.02)),\n",
        "    mf_iters=int(mf_cfg.get('iters', 30)),\n",
        "    mf_lr=float(mf_cfg.get('lr', 0.02)),\n",
        "    seed=seed,\n",
        "    ctrlite_reg=float(ctrlite_cfg.get('reg', 0.01)),\n",
        "    ctrlite_lr=float(ctrlite_cfg.get('lr', 0.1)),\n",
        "    ctrlite_iters=int(ctrlite_cfg.get('iters', 80)),\n",
        "    model='all',\n",
        "    a2f_cfg=a2f_cfg,\n",
        "    ctpf_cfg=ctpf_cfg,\n",
        "    cdl_cfg=cdl_cfg,\n",
        "    hft_cfg=hft_cfg,\n",
        "    micm_cfg=micm_cfg,\n",
        "    cmcl_cfg=cmcl_cfg,\n",
        "    backend='torch',\n",
        "    prefer_gpu=prefer_gpu,\n",
        "    mf_cfg=mf_runtime_cfg,\n",
        ")\n",
        "results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01324760",
      "metadata": {},
      "outputs": [],
      "source": [
        "for path in sorted(RUN_DIR.rglob(\"*\")):\n",
        "    if path.is_file():\n",
        "        rel = path.relative_to(PROJECT_ROOT)\n",
        "        size_kb = path.stat().st_size / 1024\n",
        "        print(f\"{rel} ({size_kb:.1f} KB)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b537ccc9",
      "metadata": {},
      "source": [
        "## Inspect metrics and buckets\n",
        "Colab runs can print the nested evaluation dictionary (with confidence intervals, per-bucket metrics, and `delta_vs_micm`) using the next cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1764b27b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "pprint(results)\n",
        "if 'cmcl' in results:\n",
        "    print('CMCL bucket snapshot:')\n",
        "    print(json.dumps(results['cmcl'].get('buckets', {}), indent=2)[:2000])\n",
        "    delta = results['cmcl'].get('delta_vs_micm')\n",
        "    if delta:\n",
        "        print('Delta vs MICM:')\n",
        "        print(json.dumps(delta, indent=2)[:2000])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}